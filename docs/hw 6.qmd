---
title: "DATA304-hw5-Portfolio"
author: "David Kim"
format: html
editor: visual
echo : FALSE
---

```{python}
import altair as alt
import pandas as pd
import json 
from urllib.request import urlopen
from vega_datasets import data
```

## Percent of men and women in various occupations 1950 and 2000.

```{python}
# (graphic 1)Percent of men and women in various occupations 1950 and 2000.

#load data
jobs_url2 = "https://cdn.jsdelivr.net/npm/vega-datasets@2.8.0/data/jobs.json"
jobs2 = pd.read_json(jobs_url2)

# Enable JSON data transformer for handling larger datasets
alt.data_transformers.enable('json')

alt.Chart(jobs2).transform_pivot(
    'year',
    value='perc',
    groupby = ["job", "sex"]).mark_point(filled=True).encode(
    x=alt.X('1950:Q', scale=alt.Scale(type='symlog',constant = 0.0001)),
    y=alt.Y('2000:Q', scale=alt.Scale(type='symlog', constant = 0.0001)),
    tooltip=['job', 'sex'],
    column = 'sex:N',

).properties(
    width=150,
    height=150
).interactive()
```

## Percent of men and women in farmer and professor occupations over time.

```{python}
# Percent of men and women in farmer and professor occupations over time.
# Load data directly from URL
jobs_url = "https://cdn.jsdelivr.net/npm/vega-datasets@2.8.0/data/jobs.json"
jobs = pd.read_json(jobs_url)

# Enable JSON data transformer for handling larger datasets
alt.data_transformers.enable('json')

# Define the chart
chart = alt.Chart(jobs).transform_filter(
    (alt.datum.job == "Farmer") | (alt.datum.job == "Professor")
).mark_line(point=True).encode(
    x='year:N',
    y=alt.Y('perc:Q' ,scale=alt.Scale(type='symlog', constant = 0.0001)),
    color=alt.Color('job:N', title="Job"),
    row = 'sex:N'
).interactive()

chart.properties(
    title="Gender Disparities in Farmer and Professor Occupations Over Time",
    width=600,
    height=100
)
```

## Number of women bakers exceeds men bakers since 1950

```{python}
import altair as alt
import pandas as pd

# Load data directly from URL
jobs_url3 = "https://cdn.jsdelivr.net/npm/vega-datasets@2.8.0/data/jobs.json"
jobs3 = pd.read_json(jobs_url3)
#print(jobs[0:4])
# Enable JSON data transformer for handling larger datasets
alt.data_transformers.enable('json')

# Define the chart
chart = alt.Chart(jobs).transform_filter(
    (alt.datum.job == "Baker") 
).mark_line(point=True).encode(
    x='year:N',
    y=alt.Y('count:Q' ,scale=alt.Scale(type='linear')),
    color=alt.Color('sex:N', title="sex"),
).interactive()

chart.properties(
    width=600,
    height=100
)
```

```{python}
# load data 
world2_url = 'https://cdn.jsdelivr.net/npm/world-atlas@2/countries-110m.json'
aux_dat = 'https://cdn.jsdelivr.net/npm/vega-datasets@1.29.0/data/gapminder.json'
aux_co = 'https://cdn.jsdelivr.net/npm/vega-datasets@1.29.0/data/gapminder-health-income.csv'

world2 = json.load(urlopen(world2_url))
auxdata = json.load(urlopen(aux_dat))
print(type(world2))
print(world2.keys())

world = alt.topo_feature(world2_url, feature='countries')

```

```{python}
country_names = [ p['properties']['name'] 
  for p in world2['objects']['countries']['geometries'] ]
print(country_names[0:5])
```

```{python}
import pandas as pd
#gapminder = pd.read_json(data.gapminder.url)
gapminder = pd.read_csv(aux_co)

common_names = list(set(country_names) & set(gapminder['country']))
missing_names = list(set(gapminder['country']) - set(country_names))
extra_names = list(set(country_names) - set(gapminder['country']))

# names in gapminder and in map data
#print("in common:", len(common_names), common_names)     
# names in gapminder but not in map data
print("missing in map:", len(missing_names), missing_names)    
# names in the map data but not in gapminder
print("extra in map", len(extra_names), extra_names)      
```

```{python}
# Existing mapping dictionary
flipped_mapping_dict = {
    'Bosnia and Herz.': 'Bosnia and Herzegovina',
    'Maldives': 'Maldives',
    'United States of America': 'United States',
    'Dem. Rep. Congo': 'Congo, Dem. Rep.',
    'Laos': 'Lao',
    'Central African Rep.': 'Central African Republic',
    'Congo': 'Congo, Rep.',
    'Czechia': 'Czech Republic',
    'S. Sudan': 'South Sudan',
    'Eq. Guinea': 'Equatorial Guinea',
    'Kiribati': 'Kiribati',
    'Sao Tome and Principe': 'Sao Tome and Principe',
    'Solomon Is.': 'Solomon Islands',
    "Côte d'Ivoire": "Cote d'Ivoire",
    'Macedonia': 'Macedonia, FYR',
    'Micronesia, Fed. Sts.': 'Micronesia, Fed. Sts.',
    'eSwatini': 'Swaziland',
    'Slovakia': 'Slovak Republic',
    'Swaziland': 'eSwatini',
    'Solomon Islands': 'Solomon Is.',
    'Equatorial Guinea': 'Eq. Guinea',
    'Macedonia, FYR': 'Macedonia',
    'Fr. S. Antarctic Lands': 'Fr. S. Antarctic Lands',
    'Czech Republic': 'Czechia',
    'Somaliland': 'Somaliland',
    'Slovak Republic': 'Slovakia',
    'Antarctica': 'Antarctica',
    'Falkland Islands': 'Falkland Is.',
    'Central African Republic': 'Central African Rep.',
    'South Sudan': 'S. Sudan',
    'United States': 'United States of America',
    'Kyrgyzstan': 'Kyrgyzstan',
    'Bosnia and Herzegovina': 'Bosnia and Herz.',
    'Dominican Republic': 'Dominican Rep.',
    'Congo, Dem. Rep.': 'Dem. Rep. Congo',
    "Cote d'Ivoire": "Côte d'Ivoire"
}

gapminder['country'] = gapminder['country'].replace(flipped_mapping_dict)

```

## Choropleth map of the World based on income

```{python}
world = alt.topo_feature(world2_url, feature='countries')
world_map = alt.Chart(world).mark_geoshape().encode(
    tooltip = ["income:Q", "properties.name:N"]
    )

world_2= world_map.transform_lookup(
  lookup='properties.name',
  from_=alt.LookupData(gapminder, 'country', ['income'])
  ).encode(
    fill = "income:Q",
    stroke = "income:Q",
    ).properties(width = 600, height = 400).project(
    type='equalEarth'
)
world_2
```

## United States state map

```{python}
us_url = "https://cdn.jsdelivr.net/npm/us-atlas@3/states-10m.json"
airport_url = "https://cdn.jsdelivr.net/npm/vega-datasets@1.29.0/data/airports.csv"

read_url = json.load(urlopen(us_url))
airport = pd.read_csv(airport_url)

states = alt.topo_feature(us_url, feature = 'states')

state_map = alt.Chart(states).mark_geoshape(
    fill = 'transparent',
    stroke = 'steelblue'
).encode(tooltip = ["properties.name:N","airport_count:Q"]).project('albersUsa')

state_map.properties(width = 500, height = 300)

```

#### Check if the state name in map datast matches the state name in auxiliary data.

```{python}
state_names = [ p['properties']['name'] 
  for p in read_url['objects']['states']['geometries'] ]
  
print(state_names[0:5])


common_names2 = list(set(state_names) & set(airport['state']))
missing_names2 = list(set(airport['state']) - set(state_names))
extra_names2 = list(set(state_names) - set(airport['state']))

# names in gapminder and in map data
print("in common:", len(common_names2), common_names2)     
# names in gapminder but not in map data
print("missing state in map:", len(missing_names2), missing_names2)    
# names in the map data but not in gapminder
print("extra state in map", len(extra_names2), extra_names2)  

state_dict = {
    'KY': 'Kentucky',
    'NE': 'Nebraska',
    'OH': 'Ohio',
    'ND': 'North Dakota',
    'PA': 'Pennsylvania',
    'NH': 'New Hampshire',
    'MN': 'Minnesota',
    'VT': 'Vermont',
    'MA': 'Massachusetts',
    'MD': 'Maryland',
    'IN': 'Indiana',
    'VA': 'Virginia',
    'HI': 'Hawaii',
    'RI': 'Rhode Island',
    'DC': 'District of Columbia',
    'NM': 'New Mexico',
    'TX': 'Texas',
    'NJ': 'New Jersey',
    'CA': 'California',
    'MI': 'Michigan',
    'AK': 'Alaska',
    'SC': 'South Carolina',
    'KS': 'Kansas',
    'GU': 'Guam',
    'CO': 'Colorado',
    'MT': 'Montana',
    'ME': 'Maine',
    'DE': 'Delaware',
    'WA': 'Washington',
    'CQ': 'Commonwealth of the Northern Mariana Islands',
    'CT': 'Connecticut',
    'PR': 'Puerto Rico',
    'AZ': 'Arizona',
    'NC': 'North Carolina',
    'UT': 'Utah',
    'NV': 'Nevada',
    'IA': 'Iowa',
    'MO': 'Missouri',
    'MS': 'Mississippi',
    'AL': 'Alabama',
    'NY': 'New York',
    'GA': 'Georgia',
    'SD': 'South Dakota',
    'OK': 'Oklahoma',
    'AR': 'Arkansas',
    'LA': 'Louisiana',
    'AS': 'American Samoa',
    'IL': 'Illinois',
    'ID': 'Idaho',
    'WV': 'West Virginia',
    'TN': 'Tennessee',
    'FL': 'Florida',
    'WI': 'Wisconsin',
    'WY': 'Wyoming',
    'OR': 'Oregon',
    'VI': 'United States Virgin Islands'
}

airport['state'] = airport['state'].replace(state_dict)
airport
```

### group up airports by state to get the count of airports in each state

```{python}
# group up airports by state to get the count of airports in each state
airport_count_per_state = airport.groupby('state').size().reset_index(name='airport_count')
airport_count_per_state
```

## Number of airport in each state

```{python}
airport_map= state_map.transform_lookup(
  lookup='properties.name',
  from_=alt.LookupData(airport_count_per_state, 'state', ['airport_count'])
  ).encode(
    fill = "airport_count:Q",
    stroke = "airport_count:Q",
    ).properties(width = 600, height = 400)
airport_map

```
